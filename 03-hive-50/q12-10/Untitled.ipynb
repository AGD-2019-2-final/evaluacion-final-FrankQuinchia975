{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext bigdata\n",
    "%hive_start\n",
    "%timeout 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -mkdir /tmp/drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: `/tmp/drivers/*': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /tmp/drivers/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tail: `/tmp/drivers/data.tsv': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -tail /tmp/drivers/data.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP TABLE IF EXISTS t0;\n",
      "OK\n",
      "Time taken: 0.157 seconds\n",
      "CREATE TABLE t0 (\n",
      "    c1 STRING,\n",
      "    c2 STRING, \n",
      "    c3 MAP<STRING, INT>\n",
      "    )\n",
      "    ROW FORMAT DELIMITED \n",
      "        FIELDS TERMINATED BY '\\t'\n",
      "        COLLECTION ITEMS TERMINATED BY ','\n",
      "        MAP KEYS TERMINATED BY '#'\n",
      "        LINES TERMINATED BY '\\n';\n",
      "OK\n",
      "Time taken: 0.065 seconds\n",
      "LOAD DATA LOCAL INPATH 'data.tsv' INTO TABLE t0;\n",
      "Loading data to table default.t0\n",
      "OK\n",
      "Time taken: 1.239 seconds\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "DROP TABLE IF EXISTS t0;\n",
    "CREATE TABLE t0 (\n",
    "    c1 STRING,\n",
    "    c2 STRING, \n",
    "    c3 MAP<STRING, INT>\n",
    "    )\n",
    "    ROW FORMAT DELIMITED \n",
    "        FIELDS TERMINATED BY '\\t'\n",
    "        COLLECTION ITEMS TERMINATED BY ','\n",
    "        MAP KEYS TERMINATED BY '#'\n",
    "        LINES TERMINATED BY '\\n';\n",
    "LOAD DATA LOCAL INPATH 'data.tsv' INTO TABLE t0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM t0;\n",
      "OK\n",
      "E\tb,g,f\t{\"jjj\":3,\"bbb\":0,\"ddd\":9,\"ggg\":8,\"hhh\":2}\n",
      "A\ta,f,c\t{\"ccc\":2,\"ddd\":0,\"aaa\":3,\"hhh\":9}\n",
      "B\tf,e,a,c\t{\"ddd\":2,\"ggg\":5,\"ccc\":6,\"jjj\":1}\n",
      "A\ta,b\t{\"hhh\":9,\"iii\":5,\"eee\":7,\"bbb\":1}\n",
      "C\tf,g,d,a\t{\"iii\":6,\"ddd\":5,\"eee\":4,\"jjj\":3}\n",
      "A\tc,d\t{\"bbb\":2,\"hhh\":0,\"ccc\":4,\"fff\":1,\"aaa\":7}\n",
      "A\tg,d,a\t{\"aaa\":5,\"fff\":8,\"ddd\":2,\"iii\":0,\"jjj\":7,\"ccc\":1}\n",
      "B\tb,a\t{\"fff\":3,\"hhh\":1,\"ddd\":2}\n",
      "E\td,e,a,f\t{\"eee\":4,\"ccc\":5,\"iii\":9,\"fff\":7,\"ggg\":6,\"bbb\":0}\n",
      "B\td,b,g,f\t{\"bbb\":7,\"jjj\":9,\"fff\":5,\"iii\":4,\"ggg\":2,\"eee\":3}\n",
      "C\td,c,f,b\t{\"hhh\":6,\"eee\":4,\"iii\":0,\"fff\":2,\"jjj\":1}\n",
      "C\td,e,a,c\t{\"bbb\":7,\"iii\":6,\"ggg\":9}\n",
      "D\tg,e,f,b\t{\"bbb\":9,\"aaa\":3,\"ccc\":6,\"fff\":4,\"eee\":2}\n",
      "E\tc,f\t{\"aaa\":8,\"ddd\":5,\"jjj\":1}\n",
      "B\td,b\t{\"ccc\":0,\"jjj\":6,\"fff\":7,\"ddd\":3,\"aaa\":2}\n",
      "D\tf,e\t{\"ccc\":0,\"eee\":6,\"bbb\":9,\"ddd\":3}\n",
      "E\te,b,f\t{\"bbb\":6,\"iii\":3,\"hhh\":5,\"fff\":4,\"ggg\":9,\"ddd\":2}\n",
      "D\tg,a\t{\"hhh\":4,\"jjj\":5,\"ccc\":9}\n",
      "E\te,c,f,a\t{\"ccc\":1,\"iii\":6,\"fff\":9}\n",
      "E\te,a\t{\"bbb\":9,\"aaa\":3,\"fff\":1}\n",
      "E\te,f\t{\"ddd\":9,\"iii\":2,\"aaa\":4}\n",
      "E\tc,b,g\t{\"ccc\":5,\"fff\":8,\"iii\":7}\n",
      "D\tc,f,a\t{\"eee\":3,\"jjj\":2,\"ddd\":7}\n",
      "A\tf,a,d\t{\"jjj\":1,\"ggg\":0,\"ccc\":7,\"ddd\":9,\"bbb\":3}\n",
      "E\tc,d\t{\"jjj\":6,\"ccc\":0,\"aaa\":1,\"hhh\":9,\"iii\":7,\"ggg\":8}\n",
      "E\te,d,c\t{\"fff\":3,\"eee\":6,\"iii\":4,\"bbb\":7,\"ddd\":0,\"ccc\":1}\n",
      "A\ta,e,f\t{\"fff\":0,\"ddd\":5,\"ccc\":4}\n",
      "E\tc,a,g\t{\"ggg\":6,\"hhh\":3,\"ddd\":9,\"ccc\":0,\"jjj\":7}\n",
      "A\tf,e\t{\"hhh\":6,\"jjj\":0,\"eee\":5,\"iii\":7,\"ccc\":3}\n",
      "C\tf,c,a,g\t{\"eee\":1,\"fff\":4,\"aaa\":2,\"ccc\":7,\"ggg\":0,\"ddd\":6}\n",
      "A\tb,f\t{\"ccc\":6,\"aaa\":9,\"eee\":5,\"ddd\":0,\"bbb\":3}\n",
      "D\tb,f\t{\"bbb\":7,\"hhh\":1,\"aaa\":6,\"iii\":4,\"fff\":9,\"ddd\":5}\n",
      "E\ta,c\t{\"fff\":3,\"ccc\":1,\"ggg\":2,\"eee\":5}\n",
      "B\tb,f,c\t{\"iii\":7,\"ggg\":3,\"ddd\":0,\"jjj\":8,\"hhh\":5,\"ccc\":1}\n",
      "B\tf,a,e\t{\"hhh\":6,\"ccc\":3,\"jjj\":0,\"bbb\":8,\"ddd\":7}\n",
      "D\ta,f\t{\"aaa\":0,\"fff\":5,\"ddd\":3}\n",
      "B\tc,a\t{\"ddd\":5,\"jjj\":2,\"iii\":7,\"ccc\":0,\"bbb\":4}\n",
      "C\tc,a,e,f\t{\"eee\":0,\"fff\":2,\"hhh\":6}\n",
      "E\te,d\t{\"fff\":9,\"iii\":2,\"eee\":0}\n",
      "E\tf,a,d\t{\"hhh\":8,\"ggg\":3,\"jjj\":5}\n",
      "Time taken: 0.253 seconds, Fetched: 40 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "SELECT * FROM t0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT   tf2, tf1.key, count (tf1.key)\n",
      "FROM t0  \n",
      "lateral view explode(split(c2, '\\\\,')) lv as tf2\n",
      "lateral view explode(c3) tf1\n",
      "GROUP BY  tf2, tf1.key;\n",
      "WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.\n",
      "Query ID = root_20200208212906_7a745bd5-d1cb-4ea7-8d3f-909d3aadde49\n",
      "Total jobs = 1\n",
      "Launching Job 1 out of 1\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1581193942430_0013, Tracking URL = http://e8ad6d4b1ea8:8088/proxy/application_1581193942430_0013/\n",
      "Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1581193942430_0013\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2020-02-08 21:29:16,764 Stage-1 map = 0%,  reduce = 0%\n",
      "2020-02-08 21:29:23,422 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.53 sec\n",
      "2020-02-08 21:29:30,066 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 6.08 sec\n",
      "MapReduce Total cumulative CPU time: 6 seconds 80 msec\n",
      "Ended Job = job_1581193942430_0013\n",
      "MapReduce Jobs Launched: \n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 6.08 sec   HDFS Read: 14893 HDFS Write: 1500 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 6 seconds 80 msec\n",
      "OK\n",
      "a\taaa\t5\n",
      "a\tbbb\t7\n",
      "a\tccc\t13\n",
      "a\tddd\t13\n",
      "a\teee\t7\n",
      "a\tfff\t10\n",
      "a\tggg\t8\n",
      "a\thhh\t8\n",
      "a\tiii\t7\n",
      "a\tjjj\t10\n",
      "b\taaa\t4\n",
      "b\tbbb\t7\n",
      "b\tccc\t5\n",
      "b\tddd\t7\n",
      "b\teee\t5\n",
      "b\tfff\t8\n",
      "b\tggg\t4\n",
      "b\thhh\t7\n",
      "b\tiii\t7\n",
      "b\tjjj\t5\n",
      "c\taaa\t5\n",
      "c\tbbb\t4\n",
      "c\tccc\t12\n",
      "c\tddd\t9\n",
      "c\teee\t6\n",
      "c\tfff\t8\n",
      "c\tggg\t7\n",
      "c\thhh\t7\n",
      "c\tiii\t8\n",
      "c\tjjj\t8\n",
      "d\taaa\t4\n",
      "d\tbbb\t6\n",
      "d\tccc\t7\n",
      "d\tddd\t5\n",
      "d\teee\t6\n",
      "d\tfff\t8\n",
      "d\tggg\t6\n",
      "d\thhh\t4\n",
      "d\tiii\t9\n",
      "d\tjjj\t8\n",
      "e\taaa\t3\n",
      "e\tbbb\t8\n",
      "e\tccc\t9\n",
      "e\tddd\t7\n",
      "e\teee\t7\n",
      "e\tfff\t9\n",
      "e\tggg\t4\n",
      "e\thhh\t4\n",
      "e\tiii\t8\n",
      "e\tjjj\t3\n",
      "f\taaa\t8\n",
      "f\tbbb\t10\n",
      "f\tccc\t13\n",
      "f\tddd\t17\n",
      "f\teee\t11\n",
      "f\tfff\t11\n",
      "f\tggg\t9\n",
      "f\thhh\t10\n",
      "f\tiii\t10\n",
      "f\tjjj\t12\n",
      "g\taaa\t3\n",
      "g\tbbb\t3\n",
      "g\tccc\t6\n",
      "g\tddd\t5\n",
      "g\teee\t4\n",
      "g\tfff\t5\n",
      "g\tggg\t4\n",
      "g\thhh\t3\n",
      "g\tiii\t4\n",
      "g\tjjj\t6\n",
      "Time taken: 25.289 seconds, Fetched: 70 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "SELECT   tf2, tf1.key, count (tf1.key)\n",
    "FROM t0  \n",
    "lateral view explode(split(c2, '\\\\,')) lv as tf2\n",
    "lateral view explode(c3) tf1\n",
    "GROUP BY  tf2, tf1.key;\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT   tf2\n",
      "FROM t0  \n",
      "lateral view explode(split(c2, '\\\\,')) lv as tf2\n",
      "GROUP BY  tf2;\n",
      "WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.\n",
      "Query ID = root_20200208212817_327c1936-bba1-47a0-9bd4-6f7452a9efd5\n",
      "Total jobs = 1\n",
      "Launching Job 1 out of 1\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1581193942430_0012, Tracking URL = http://e8ad6d4b1ea8:8088/proxy/application_1581193942430_0012/\n",
      "Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1581193942430_0012\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2020-02-08 21:28:27,224 Stage-1 map = 0%,  reduce = 0%\n",
      "2020-02-08 21:28:35,120 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.76 sec\n",
      "2020-02-08 21:28:42,978 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 6.8 sec\n",
      "MapReduce Total cumulative CPU time: 6 seconds 800 msec\n",
      "Ended Job = job_1581193942430_0012\n",
      "MapReduce Jobs Launched: \n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 6.8 sec   HDFS Read: 11662 HDFS Write: 185 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 6 seconds 800 msec\n",
      "OK\n",
      "a\n",
      "b\n",
      "c\n",
      "d\n",
      "e\n",
      "f\n",
      "g\n",
      "Time taken: 27.986 seconds, Fetched: 7 row(s)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%hive\n",
    "SELECT   tf2\n",
    "FROM t0  \n",
    "lateral view explode(split(c2, '\\\\,')) lv as tf2\n",
    "GROUP BY  tf2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
